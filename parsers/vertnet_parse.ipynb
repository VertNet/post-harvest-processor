{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Extract Traits from the VertNet Database](#Extract-Traits-from-the-VertNet-Database)\n",
    "\t* [Introduction](#Introduction)\n",
    "\t\t* [General Approach for Extraction](#General-Approach-for-Extraction)\n",
    "\t\t* [Constants Used During the Extraction](#Constants-Used-During-the-Extraction)\n",
    "\t\t* [Look at the Words in the Target Cells](#Look-at-the-Words-in-the-Target-Cells)\n",
    "\t\t* [Regular Expression Objects](#Regular-Expression-Objects)\n",
    "\t* [Sex Parsing](#Sex-Parsing)\n",
    "\t\t* [Sex Parsing Regular Expression Battery](#Sex-Parsing-Regular-Expression-Battery)\n",
    "\t\t* [Test Sex Parsing](#Test-Sex-Parsing)\n",
    "\t* [Life Stage Parsing](#Life-Stage-Parsing)\n",
    "\t\t* [Life Stage Parsing Regular Expression Battery](#Life-Stage-Parsing-Regular-Expression-Battery)\n",
    "\t\t* [Test Life Stage Parsing](#Test-Life-Stage-Parsing)\n",
    "\t* [Common Regular Expression Fragments for Both Length and Mass Trait Parsing](#Common-Regular-Expression-Fragments-for-Both-Length-and-Mass-Trait-Parsing)\n",
    "\t* [Total Length Parsing](#Total-Length-Parsing)\n",
    "\t\t* [Common Total Length Parsing Regular Expression Fragments](#Common-Total-Length-Parsing-Regular-Expression-Fragments)\n",
    "\t\t* [Total Length Parsing Regular Expression Battery](#Total-Length-Parsing-Regular-Expression-Battery)\n",
    "\t\t* [Test Total Length Parsing](#Test-Total-Length-Parsing)\n",
    "\t* [Body Mass Parsing](#Body-Mass-Parsing)\n",
    "\t\t* [Common Body Mass Parsing Regular Expression Fragments](#Common-Body-Mass-Parsing-Regular-Expression-Fragments)\n",
    "\t\t* [Body Mass Parsing Regular Expression Battery](#Body-Mass-Parsing-Regular-Expression-Battery)\n",
    "\t\t* [Test Body Mass Parsing](#Test-Body-Mass-Parsing)\n",
    "\t* [Extract the Traits](#Extract-the-Traits)\n",
    "\t\t* [Extract the Raw Trait Values](#Extract-the-Raw-Trait-Values)\n",
    "\t\t* [Look at Extracted Keys and Units](#Look-at-Extracted-Keys-and-Units)\n",
    "\t\t* [Conversion Factors for Total Length and Body Mass Traits](#Conversion-Factors-for-Total-Length-and-Body-Mass-Traits)\n",
    "\t\t* [Normalize the Total Length and Body Mass Traits](#Normalize-the-Total-Length-and-Body-Mass-Traits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Traits from the VertNet Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Welcome to the thrilling world of parsing irregularly structured text!**\n",
    "\n",
    "We're going to extract the following traits from an extract of the [VertNet database](http://vertnet.org/):\n",
    "- Sex\n",
    "- Life stage\n",
    "- Total length (or a commonly used measure often substituted for total length: E.g. Snout-Vent Length)\n",
    "- Body mass (look for common body mass substitutes too)\n",
    "\n",
    "We are looking for the traits in these columns of the VertNet database:\n",
    "- dynamicproperties (This will be the preferred column for extracting values)\n",
    "- occurrenceremarks\n",
    "- fieldnotes\n",
    "\n",
    "We will append the extracted data to new columns in each row.\n",
    "\n",
    "We're exploiting the fact that most of the data is in a structured or semi-structured format.\n",
    "\n",
    "**Note**: This an early version and, as such, it uses an *Ad hoc* approach with regular expressions. **This will not scale to other trait extractions.** We will need to use other techniques for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Approach for Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to loop through a each row in the CSV file and scan for the trait in each of the column cells. The scanning will involve an ordered battery of regular expressions for each trait. Once a trait is found for the CSV cell we will stop scanning that particular cell for the trait and move on to the next cell.  That means that we may find the same trait for a row in each of the scanned cells. For example: We may find a sex in both dynamicproperties and occurrenceremarks and we will record both. Once we have scanned all cells in a row for a trait we will then move on to scan all cells in the row for the next trait. And so on.  **The order of the regular expressions is important.**\n",
    "\n",
    "We will add a new column for each trait being extracted. That column will contain a JSON object with an array of objects like so:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>...rest of CSV row...</th>\n",
    "        <th>autoextract_body_length</th>\n",
    "        <th>...other extracted columns...</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>orginal data is untouched</td>\n",
    "        <td>{\"dynamicproperties\":{\"key\":\"totalLengthInMM\",\"units\":\"MM\",\"value\":\"270\"},\n",
    "        \"fieldnotes\":{\"key\":\"total length\",\"units\":\"mm\",\"value\":\"270.0\"}}</td>\n",
    "        <td>other extracted data</td>\n",
    "    </tr>\n",
    "    \n",
    "</table>\n",
    "\n",
    "The object will have the column we extracted the trait from as a column key. Therefore, there will be up to three fields in the object (In the example above there was nothing for the \"occurrenceremarks\" column.):\n",
    "- key: AKA the regex key. (Two keys are a bit confusing.) This is what we're looking for to extract the value.\n",
    "- value: This is a number or a number range for the value. Or a word or phrase for class values.\n",
    "- units: For measurements with numbers we also try to extract the units associated with the value.\n",
    "\n",
    "**Note**: We do not try to interpret any of the values we are only extracting them. We will interpret the data at a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "import regex   # re expressions lack desired features\n",
    "import datetime\n",
    "import unittest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants Used During the Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data directory\n",
    "DATA_DIR = '../data/'\n",
    "\n",
    "# The file containing the original VertNet extraction\n",
    "VERTNET_FILE_NAME = os.path.join(DATA_DIR, 'vn_20151028_orems_fnotes_dprops_not_null')\n",
    "\n",
    "# Used in file names\n",
    "# now = datetime.datetime.now().strftime(\"_%Y%m%d_%H%M_\")\n",
    "BASE_FILE_NAME = VERTNET_FILE_NAME + '_'\n",
    "\n",
    "# The file containing the parsed VertNet traits\n",
    "RAW_FILE_NAME = BASE_FILE_NAME + 'raw.csv'\n",
    "\n",
    "# The file containing the normalized VertNet traits\n",
    "NORMALIZED_FILE_NAME = BASE_FILE_NAME + 'norm.csv'\n",
    "\n",
    "# A file containing all of the raw words in the target columns -- used to search for stem words\n",
    "WORDS_FILE_NAME = BASE_FILE_NAME + 'words.txt'\n",
    "\n",
    "# We will search these VerNet columns to extract the traits\n",
    "# We use the order during normalization\n",
    "VERTNET_SEARCH_COLUMNS = [\n",
    "    'dynamicproperties',\n",
    "    'occurrenceremarks',\n",
    "    'fieldnotes'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Words in the Target Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of what kinds of data are in the cells have a look at the different words in the cells. After examining those words, we can start to get an idea of what regular expressions to write and which words to use as anchors for the regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_words_in_cells(csv_dict_reader, search_columns):\n",
    "    # For this, we consider dots as letters\n",
    "    punctuation = regex.compile(r'[^\\p{Letter}.]+')\n",
    "    \n",
    "    words = Counter()\n",
    "    \n",
    "    for row in csv_dict_reader:\n",
    "        extracted_words = []\n",
    "        \n",
    "        for column in search_columns:\n",
    "            extracted_words.extend(punctuation.split(row[column]))\n",
    "    \n",
    "        for word in extracted_words:\n",
    "            words[word.lower()] += 1\n",
    "    \n",
    "    return sorted(words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "format": "row",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_all_words():\n",
    "    with open(VERTNET_FILE_NAME, 'r') as in_file:\n",
    "        reader = csv.DictReader(in_file)\n",
    "        words = get_words_in_cells(reader, VERTNET_SEARCH_COLUMNS)\n",
    "\n",
    "    with open(WORDS_FILE_NAME, 'w') as out_file:\n",
    "        for word in words:\n",
    "            out_file.write(word + '\\n')\n",
    "\n",
    "\n",
    "# get_all_words()  # Uncomment me to get the list of words used in the columns being searched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expressions require common supporting logic so they are packaged into an object. Then we will use an array of these objects for the actual parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Regexp:\n",
    "    def __init__(self, name, regexp,\n",
    "                 want_array=False,\n",
    "                 parse_units=False,\n",
    "                 default_key=None,\n",
    "                 default_units=None,\n",
    "                 units_from_key=None,\n",
    "                 compound_value=False):\n",
    "        self.name = name\n",
    "        self.regexp = regex.compile(\n",
    "            regexp,\n",
    "            regex.IGNORECASE | regex.VERBOSE)\n",
    "        self.want_array     = want_array\n",
    "        self.parse_units    = parse_units\n",
    "        self.default_key    = default_key\n",
    "        self.default_units  = default_units\n",
    "        self.compound_value = compound_value\n",
    "        self.units_from_key = units_from_key\n",
    "\n",
    "    def _get_key_(self, match):\n",
    "        key = None\n",
    "        if 'key' in match.groupdict().keys():\n",
    "            key = match.group('key')\n",
    "        if not key:\n",
    "            key = self.default_key\n",
    "        return key\n",
    "\n",
    "    def _get_value_(self, match):\n",
    "        if 'value' in match.groupdict().keys():\n",
    "            return match.group('value')\n",
    "        return [match.group('value1'), match.group('value2')]\n",
    "\n",
    "    def _get_units_(self, match, key):\n",
    "        units = None\n",
    "        if 'units' in match.groupdict().keys():\n",
    "            units = match.group('units')\n",
    "        if 'units1' in match.groupdict().keys():\n",
    "            units = [match.group('units1'), match.group('units2')]\n",
    "        if not units and key:\n",
    "            u = self.units_from_key.search(key)\n",
    "            if u:\n",
    "                units = u.group('units')\n",
    "        if not units:\n",
    "            units = self.default_units\n",
    "        return units\n",
    "\n",
    "    def _get_value_array_(self, string):\n",
    "        matches = self.regexp.findall(string)\n",
    "        if matches:\n",
    "            return dict(key=None, value=matches)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def matches(self, string):\n",
    "        if self.want_array:\n",
    "            return self._get_value_array_(string)\n",
    "\n",
    "        match = self.regexp.search(string)\n",
    "        if not match:\n",
    "            return None\n",
    "\n",
    "        parsed = dict()\n",
    "        parsed['key']   = self._get_key_(match)\n",
    "        parsed['value'] = self._get_value_(match)\n",
    "        if self.parse_units:\n",
    "            parsed['units'] = self._get_units_(match, parsed['key'])\n",
    "\n",
    "        return parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an carefully ordered array of regular expressions to look for traits in the database. There is some logic for dealing with the entire array of regular expressions, this is captured in the following object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RegexpBattery:\n",
    "    def __init__(self, exclude_pattern=None, parse_units=False, units_from_key=None):\n",
    "        self.exclude_pattern = exclude_pattern\n",
    "        if exclude_pattern:\n",
    "            self.exclude_pattern = regex.compile(\n",
    "                exclude_pattern,\n",
    "                regex.IGNORECASE | regex.VERBOSE)\n",
    "\n",
    "        self.units_from_key = units_from_key\n",
    "        if units_from_key:\n",
    "            self.units_from_key = regex.compile(\n",
    "                units_from_key,\n",
    "                regex.IGNORECASE | regex.VERBOSE)\n",
    "\n",
    "        self.battery     = []\n",
    "        self.parse_units = parse_units\n",
    "\n",
    "    def _excluded_(self, match):\n",
    "        if self.exclude_pattern and match and isinstance(match['value'], str):\n",
    "            return self.exclude_pattern.search(match['value'])\n",
    "        return False\n",
    "    \n",
    "    def append(self, *args, **kwargs):\n",
    "        regexp = Regexp(*args, **kwargs)\n",
    "        self.battery.append(regexp)\n",
    "        regexp.parse_units    = self.parse_units\n",
    "        regexp.units_from_key = self.units_from_key\n",
    "    \n",
    "    def parse(self, string):\n",
    "        for regexp in self.battery:\n",
    "            match = regexp.matches(string)\n",
    "            if match and not self._excluded_(match):\n",
    "                # print(regexp.name)\n",
    "                return match\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sex Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex Parsing Regular Expression Battery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expressions:\n",
    "- First we look for a keyword for sex and its value. We try and get a string of words for the value by looking for a delimiter after the value.\n",
    "- If no delimiter is found then just return the word that follows the keyword.\n",
    "- Failing that, we look for the words \"male\" or \"female\" in the cells. Here we want to return all matches not just one so that we don't seem more sure of the value than we should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SEX = RegexpBattery(exclude_pattern=r''' ^ (?: and | was | is ) $ ''')\n",
    "\n",
    "# Look for a key and value that is terminated with a delimiter\n",
    "SEX.append(\n",
    "    'sex_key_value_delimited',\n",
    "    r'''\n",
    "        \\b (?P<key> sex)\n",
    "        \\W+\n",
    "        (?P<value> [\\w?.]+ (?: \\s+ [\\w?.]+ ){0,2} )\n",
    "        \\s* (?: [:;,\"] | $ )\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Look for a key and value without a clear delimiter\n",
    "SEX.append(\n",
    "    'sex_key_value_undelimited',\n",
    "    r'''\n",
    "         \\b (?P<key> sex) \\W+ (?P<value> \\w+ )\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Look for the words male & female\n",
    "SEX.append(\n",
    "    'sex_unkeyed',\n",
    "    r'''\n",
    "        \\b (?P<value> (?: males? | females? ) (?: \\s* \\? )? ) \\b\n",
    "    ''',\n",
    "    want_array=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Sex Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=5 errors=0 failures=0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = SEX\n",
    "\n",
    "class TestSexParsing(unittest.TestCase):\n",
    "\n",
    "    def test_sex_key_value_delimited_1(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('weight=81.00 g; sex=female ? ; age=u ad.'),\n",
    "            {'key': 'sex', 'value': 'female ?'})\n",
    "\n",
    "    def test_sex_key_value_delimited_2(self):\n",
    "        self.assertDictEqual(\n",
    "            SEX.parse('sex=unknown ; crown-rump length=8 mm'),\n",
    "            {'key': 'sex', 'value': 'unknown'})\n",
    "\n",
    "    def test_sex_key_value_undelimited_1(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('sex=F crown rump length=8 mm'),\n",
    "            {'key': 'sex', 'value': 'F'})\n",
    "\n",
    "    def test_sex_unkeyed_1(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('words male female unknown more words'),\n",
    "            {'key': None, 'value': ['male', 'female']})\n",
    "\n",
    "    def test_excluded_1(self):\n",
    "        self.assertEqual(\n",
    "            target.parse('Respective sex and msmt. in mm'),\n",
    "            None)\n",
    "\n",
    "suite = unittest.defaultTestLoader.loadTestsFromTestCase(TestSexParsing)\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Life Stage Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Life Stage Parsing Regular Expression Battery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expressions:\n",
    "- First we look for a keyword for life stage and its value. We try and get a string of words for the value by looking for a delimiter after the value.\n",
    "- If no delimiter is found then return known life stage phrases that follow the keyword.\n",
    "- Failing that, we look for phrases that are associated with life stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LIFE_STAGE = RegexpBattery(\n",
    "    exclude_pattern=r''' ^ determin ''')\n",
    "\n",
    "# Common regular expression fragments for parsing life stage\n",
    "LIFE_STAGE_FRAGMENTS = r'''\n",
    "    (?(DEFINE)\n",
    "        (?P<word_chars> [\\w?.\\/\\-]+ )\n",
    "    )\n",
    "'''\n",
    "\n",
    "# Look for a key and value that is terminated with a delimiter\n",
    "LIFE_STAGE.append(\n",
    "    'life_stage_key_value_delimited',\n",
    "    LIFE_STAGE_FRAGMENTS + r'''\n",
    "        \\b (?P<key> (?: life \\s* stage (?: \\s* remarks )? | age (?: \\s* class )? ) )\n",
    "           \\W+\n",
    "           (?P<value> (?&word_chars) (?: \\s+(?&word_chars) ){0,4} ) \\s*\n",
    "           (?: [:;,\"] | $ )\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Look for a key and value without a clear delimiter\n",
    "LIFE_STAGE.append(\n",
    "    'life_stage_key_value_undelimited',\n",
    "    LIFE_STAGE_FRAGMENTS + r'''\n",
    "        \\b (?P<key> life \\s* stage (?: \\s* remarks )?\n",
    "                  | age \\s* class\n",
    "                  | age \\s* in \\s* (?: hour | day ) s?\n",
    "                  | age\n",
    "            )\n",
    "            \\W+\n",
    "            (?P<value> [\\w?.\\/\\-]+ (?: \\s+ (?: year | recorded ) )? )\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Look for common life stage phrases\n",
    "LIFE_STAGE.append(\n",
    "    'life_stage_no_keyword',\n",
    "    LIFE_STAGE_FRAGMENTS + r'''\n",
    "        (?P<value> (?: after \\s+ )?\n",
    "                   (?: first | second | third | fourth | hatching ) \\s+\n",
    "                   year )\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Life Stage Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=6 errors=0 failures=0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = LIFE_STAGE\n",
    "\n",
    "class TestLifeStageParsing(unittest.TestCase):\n",
    "\n",
    "    def test_life_stage_key_value_delimited_1(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('sex=unknown ; age class=adult/juvenile'),\n",
    "            {'key': 'age class', 'value': 'adult/juvenile'})\n",
    "\n",
    "    def test_life_stage_key_value_delimited_2(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('weight=81.00 g; sex=female ? ; age=u ad.'),\n",
    "            {'key': 'age', 'value': 'u ad.'})\n",
    "\n",
    "    def test_life_stage_key_value_delimited_3(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('weight=5.2 g; age class=over-winter ; total length=99 mm;'),\n",
    "            {'key': 'age class', 'value': 'over-winter'})\n",
    "\n",
    "    def test_life_stage_key_value_undelimited_1(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('sex=female ? ; age=1st year more than four words here'),\n",
    "            {'key': 'age', 'value': '1st year'})\n",
    "\n",
    "    def test_life_stage_no_keyword_1(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('words after hatching year more words'),\n",
    "            {'key': None, 'value': 'after hatching year'})\n",
    "\n",
    "    def test_excluded_1(self):\n",
    "        self.assertEqual(\n",
    "            target.parse('age determined by 20-sided die'),\n",
    "            None)\n",
    "\n",
    "    def test_life_stage_no_keyword_1(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('LifeStage Remarks: 5-6 wks'),\n",
    "            {'key': 'LifeStage Remarks', 'value': '5-6 wks'})\n",
    "        \n",
    "suite = unittest.defaultTestLoader.loadTestsFromTestCase(TestLifeStageParsing)\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Regular Expression Fragments for Both Length and Mass Trait Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length and Mass regular expressions use many of the same parsing fragments repeatedly. We group them here and append them to the regular expressions in the batteries.\n",
    "\n",
    "One common abbreviation that is used in both mass and length traits is in the form of: 181-75-21-18=22. The first number is always the total length in millimeters and the last number is the body mass. The other numbers are various length measurements that we are not extracting at this time. The first number (total length) is easy to extract but the last number is typically, but not always, preceded by an equal sign. Things to be careful about when parsing this form:\n",
    "- We do not want to mistake a date for this shorthand notation.\n",
    "- If the last number is not preceded by an equal sign or not followed by a mass unit (which makes the parsing easy) then we will consider the last number to be a mass if there are at least 5 numbers in the sequence.\n",
    "- There is also a simplifying form for the shorthand like: 83-0-17-23-fa64-35. We consider the last number after the \"fa\" number to be the total mass.\n",
    "- We have to be careful to not mistake these shorthand notations for number ranges like 10.5-20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MASS_LENGTH_FRAGMENTS = r'''\n",
    "    (?(DEFINE)\n",
    "    \n",
    "        # For our purposes numbers are always positive and decimals.\n",
    "        (?P<number> (?&open) (?: \\d{1,3} (?: , \\d{3} ){1,3} | \\d+ ) (?: \\. \\d+ )? (?&close) [\\*]? )\n",
    "       \n",
    "        # We also want to pull in number ranges when appropriate.\n",
    "        (?P<range> (?&number) (?: \\s* (?: - | to ) \\s* (?&number) )? )\n",
    "\n",
    "        # Characters that follow a keyword\n",
    "        (?P<key_end>  \\s* [^\\w.\\[\\(]* \\s* )\n",
    "        \n",
    "        # We sometimes want to guarantee no word precedes another word.\n",
    "        # This cannot be done with negative look behind, so we do a positive search for a separator\n",
    "        (?P<no_word>  (?: ^ | [;,:\"'\\{\\[\\(]+ ) \\s* )\n",
    "\n",
    "        # Keywords that may precedes a shorthand measurement\n",
    "        (?P<shorthand_words> on \\s* tag\n",
    "                           | specimens?\n",
    "                           | catalog\n",
    "                           | measurements (?: \\s+ [\\p{Letter}]+)\n",
    "                           | tag \\s+ \\d+ \\s* =? (?: male | female)? \\s* ,\n",
    "                           | meas [.,]? (?: \\s+ \\w+ \\. \\w+ \\. )?\n",
    "        )\n",
    "        \n",
    "        # Common keyword misspellings that precede shorthand measurement\n",
    "        (?P<shorthand_typos>  mesurements | Measurementsnt )\n",
    "        \n",
    "        # Keys where we need units to know if it's for mass or length\n",
    "        (?P<key_units_req> measurements? | body | total )\n",
    "        \n",
    "        # Characters that separate shorthand values\n",
    "        (?P<shorthand_sep> [:\\/\\-\\s] )\n",
    "        \n",
    "        # Used in shorthand notation for unknown values\n",
    "        (?P<shorthand_unknown> [?x] )\n",
    "\n",
    "        # Look for an optional dash or space character\n",
    "        (?P<dash>     [\\s\\-]? )\n",
    "        (?P<dash_req> [\\s\\-]  )\n",
    "        \n",
    "        # Look for an optional dot character\n",
    "        (?P<dot> \\.? )\n",
    "        \n",
    "        # Numbers are sometimes surrounded by brackets or parentheses\n",
    "        # Don't worry about matching the opening and closing brackets\n",
    "        (?P<open>  [\\(\\[\\{]? )\n",
    "        (?P<close> [\\)\\]\\}]? )\n",
    "    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Length Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Total Length Parsing Regular Expression Fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LENGTH_FRAGMENTS = MASS_LENGTH_FRAGMENTS + r'''\n",
    "    (?(DEFINE)\n",
    "\n",
    "        # Look for a shorthand total length. Make sure this isn't a date\n",
    "        (?P<len_shorthand> (?&dash_req) (?: (?&number) | (?&shorthand_unknown) )\n",
    "                           (?: (?&shorthand_sep)\n",
    "                               (?: (?&number) | (?&shorthand_unknown) ) ){2,}\n",
    "        )\n",
    "\n",
    "        # The \"European\" version of the shorthand length\n",
    "        (?P<len_shorthand_euro> (?&dash_req) (?: (?&number) | (?&shorthand_unknown) )\n",
    "                                (?: (?&shorthand_sep)\n",
    "                                (?: (?<! [\\w\\-] ) (?&number) | (?&shorthand_unknown) )\n",
    "                                [\\p{Letter}]{0,3} ){2,}\n",
    "        )\n",
    "\n",
    "        # Keys that indicate we have a total length\n",
    "        (?P<total_len_key> total  (?&dash) length (?&dash) in (?&dash) mm\n",
    "                         | length (?&dash) in     (?&dash) millimeters\n",
    "                         | (?: total | max | standard ) (?&dash) lengths?\n",
    "        )\n",
    "\n",
    "        # Snout-vent length is sometimes used as a proxy for total length in some groups\n",
    "        (?P<svl_len_key> snout  (?&dash) vent   (?&dash) lengths? (?: (?&dash) in (?&dash) mm )?\n",
    "                       | s (?&dot) v (?&dot) l (?&dot)\n",
    "                       | snout \\s+ vent \\s+ lengths?\n",
    "        )\n",
    "\n",
    "        # Other keys that may be used as a proxy for total length for some groups\n",
    "        (?P<other_len_key> head  (?&dash) body (?&dash) length (?&dash) in (?&dash) millimeters\n",
    "                         | (?: fork | mean | body ) (?&dash) lengths?\n",
    "                         | t [o.]? l (?&dot) _?\n",
    "        )\n",
    "\n",
    "        # Ambiguous length keys\n",
    "        (?P<len_key_ambiguous> lengths? | tag )\n",
    "\n",
    "        # Abbreviations for total length\n",
    "        (?P<len_key_abbrev> t (?&dot) o? l (?&dot) | s (?&dot) l (?&dot) )\n",
    "\n",
    "        # For when the key is a suffix like: 44 mm TL\n",
    "        (?P<len_key_suffix> (?: in \\s* )? (?&len_key_abbrev) )\n",
    "\n",
    "        # Gather all length key types\n",
    "        (?P<all_len_keys> (?&total_len_key)\n",
    "                        | (?&svl_len_key)\n",
    "                        | (?&other_len_key)\n",
    "                        | (?&len_key_ambiguous)\n",
    "                        | (?&key_units_req)\n",
    "                        | (?&shorthand_words)\n",
    "                        | (?&shorthand_typos)\n",
    "        )\n",
    "\n",
    "        # Length keys found in phrases\n",
    "        (?P<len_in_phrase> (?: total \\s+ length | snout \\s+ vent \\s+ length | standard \\s+ length ) s? )\n",
    "\n",
    "        # Length unit words\n",
    "        (?P<len_units_word> (?: meter | millimeter | centimeter | foot | feet | inch e? ) s? )\n",
    "\n",
    "        # Length unit abbreviations\n",
    "        (?P<len_units_abbrev> (?: [cm] (?&dot) m | in | ft ) (?&dot) s? )\n",
    "\n",
    "        # All length units\n",
    "        (?P<len_units> (?&len_units_word) | (?&len_units_abbrev) )\n",
    "\n",
    "        # Used for parsing forms like: 2 ft 4 inches\n",
    "        (?P<len_foot> (?: foot | feet | ft ) s? (?&dot) )\n",
    "        (?P<len_inch> (?: inch e? | in )     s? (?&dot) )\n",
    "    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Length Parsing Regular Expression Battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TOTAL_LENGTH = RegexpBattery(parse_units=True, units_from_key=r''' (?P<units> mm | millimeters ) $ ''')\n",
    "\n",
    "# Look for a pattern like: total length: 4 ft 8 in\n",
    "TOTAL_LENGTH.append(\n",
    "    'en_len',\n",
    "    LENGTH_FRAGMENTS + r'''\n",
    "        \\b (?P<key> (?&all_len_keys))? (?&key_end)?\n",
    "           (?P<value1> (?&range))    \\s*\n",
    "           (?P<units1> (?&len_foot)) \\s*\n",
    "           (?P<value2> (?&range))    \\s*\n",
    "           (?P<units2> (?&len_inch))\n",
    "    ''',\n",
    "    default_key='_english_',\n",
    "    compound_value=2\n",
    ")\n",
    "\n",
    "# Look for total key, number (not a range) and optional units\n",
    "# Like: total length = 10.5 mm\n",
    "TOTAL_LENGTH.append(\n",
    "    'total_len_key_num',\n",
    "    LENGTH_FRAGMENTS + r'''\n",
    "        \\b (?P<key>   (?&total_len_key)) (?&key_end)\n",
    "           (?P<value> (?&number)) (?! [\\d\\-\\.] ) \\s*\n",
    "           (?P<units> (?&len_units))?\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Look for these secondary length keys next but allow a range\n",
    "TOTAL_LENGTH.append(\n",
    "    'other_len_key',\n",
    "    LENGTH_FRAGMENTS + r'''\n",
    "        \\b (?P<key>   (?&other_len_key)) (?&key_end)\n",
    "           (?P<value> (?&range)) \\s*\n",
    "           (?P<units> (?&len_units))?\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Look for keys where the units are required\n",
    "TOTAL_LENGTH.append(\n",
    "    'key_units_req',\n",
    "    LENGTH_FRAGMENTS + r'''\n",
    "        \\b (?P<key> (?&key_units_req)) (?&key_end)\n",
    "        (?P<value> (?&range)) \\s*\n",
    "        (?P<units> (?&len_units))\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Look for a length in a phrase\n",
    "TOTAL_LENGTH.append(\n",
    "    'len_in_phrase',\n",
    "    LENGTH_FRAGMENTS + r'''\n",
    "        \\b (?P<key>   (?&len_in_phrase)) \\D{1,32}\n",
    "           (?P<value> (?&range)) \\s*\n",
    "           (?P<units> (?&len_units))?\n",
    "    '''\n",
    ")\n",
    "\n",
    "# These keys require units to disambiguate what is being measured\n",
    "TOTAL_LENGTH.append(\n",
    "    'len_key_ambiguous_units',\n",
    "    LENGTH_FRAGMENTS + r'''\n",
    "        (?&no_word)\n",
    "        (?P<key>   (?&len_key_ambiguous)) (?&key_end)\n",
    "        (?P<value> (?&range)) \\s*\n",
    "        (?P<units> (?&len_units))\n",
    "    '''\n",
    ")\n",
    "\n",
    "# An out of order parse: tol (mm) 20-25\n",
    "TOTAL_LENGTH.append(\n",
    "    'len_key_abbrev',\n",
    "    LENGTH_FRAGMENTS + r'''\n",
    "        \\b (?P<key>   (?&len_key_abbrev)) \\s*\n",
    "           (?&open)  \\s* (?P<units> (?&len_units)) \\s* (?&close) \\s*\n",
    "           (?P<value> (?&range))\n",
    "    '''\n",
    ")\n",
    "\n",
    "# This parse puts the key at the end: 20-25 mm TL\n",
    "TOTAL_LENGTH.append(\n",
    "    'len_key_suffix',\n",
    "    LENGTH_FRAGMENTS + r'''\n",
    "        \\b (?P<value> (?&range)) \\s*\n",
    "           (?P<units> (?&len_units))? \\s*\n",
    "           (?P<key>   (?&len_key_suffix))\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Length is in shorthand notation\n",
    "TOTAL_LENGTH.append(\n",
    "    'len_shorthand',\n",
    "    LENGTH_FRAGMENTS + r'''\n",
    "        \\b (?: (?P<key> (?&all_len_keys)) (?&key_end) )?\n",
    "           (?P<value>   (?&number))\n",
    "           (?&len_shorthand)\n",
    "    ''',\n",
    "    default_units='_mm_',\n",
    "    default_key='_shorthand_'\n",
    ")\n",
    "\n",
    "# A shorthand notation with some abbreviations in it\n",
    "TOTAL_LENGTH.append(\n",
    "    'len_shorthand_euro',\n",
    "    LENGTH_FRAGMENTS + r'''\n",
    "        \\b (?: (?P<key> (?&all_len_keys)) (?&key_end) )?\n",
    "           [a-z]*\n",
    "           (?P<value>   (?&number))\n",
    "           (?&len_shorthand_euro)\n",
    "    ''',\n",
    "    default_units='_mm_',\n",
    "    default_key='_shorthand_'\n",
    ")\n",
    "\n",
    "# Now we can look for the total length, RANGE, optional units\n",
    "# See 'total_len_key_num' above\n",
    "TOTAL_LENGTH.append(\n",
    "    'total_len_key',\n",
    "    LENGTH_FRAGMENTS + r'''\n",
    "        \\b (?P<key>   (?&total_len_key)) (?&key_end)\n",
    "           (?P<value> (?&range)) \\s*\n",
    "           (?P<units> (?&len_units))?\n",
    "    '''\n",
    ")\n",
    "\n",
    "# We will now allow an ambiguous key if it is not preceded by another word\n",
    "TOTAL_LENGTH.append(\n",
    "    'len_key_ambiguous',\n",
    "    LENGTH_FRAGMENTS + r'''\n",
    "        (?&no_word)\n",
    "        (?P<key>   (?&len_key_ambiguous)) (?&key_end)\n",
    "        (?P<value> (?&range))\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Look for snout-vent length keys\n",
    "TOTAL_LENGTH.append(\n",
    "    'svl_len_key',\n",
    "    LENGTH_FRAGMENTS + r'''\n",
    "        \\b (?P<key>   (?&svl_len_key)) (?&key_end)\n",
    "           (?P<value> (?&range)) \\s*\n",
    "           (?P<units> (?&len_units))?\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Total Length Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "............................................\n",
      "----------------------------------------------------------------------\n",
      "Ran 44 tests in 0.088s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=44 errors=0 failures=0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = TOTAL_LENGTH\n",
    "\n",
    "class TestTotalLengthParsing(unittest.TestCase):\n",
    "\n",
    "    def test_units_from_key(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('{\"totalLengthInMM\":\"123\" };'),\n",
    "            {'key': 'totalLengthInMM', 'value': '123', 'units': 'MM'})\n",
    "    \n",
    "    def test_0(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('measurements: ToL=230;TaL=115;HF=22;E=18; total length=230 mm; tail length=115 mm;'),\n",
    "            {'key': 'total length', 'value': '230', 'units': 'mm'})\n",
    "    \n",
    "    def test_1(self):\n",
    "        self.assertEqual(\n",
    "            target.parse('sex=unknown ; crown-rump length=8 mm'),\n",
    "            None)\n",
    "    \n",
    "    def test_2(self):\n",
    "        self.assertEqual(\n",
    "            target.parse('left gonad length=10 mm; right gonad length=10 mm;'),\n",
    "            None)\n",
    "    \n",
    "    def test_3(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('\"{\"measurements\":\"308-190-45-20\" }\"'),\n",
    "            {'key': 'measurements', 'value': '308', 'units': '_mm_'})\n",
    "    \n",
    "    def test_4(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('308-190-45-20'),\n",
    "            {'key': '_shorthand_', 'value': '308', 'units': '_mm_'})\n",
    "    \n",
    "    def test_5(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('{\"measurements\":\"143-63-20-17=13 g\" }'),\n",
    "            {'key': 'measurements', 'value': '143', 'units': '_mm_'})\n",
    "    \n",
    "    def test_6(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('143-63-20-17=13'),\n",
    "            {'key': '_shorthand_', 'value': '143', 'units': '_mm_'})\n",
    "    \n",
    "    def test_7(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('snout-vent length=54 mm; total length=111 mm; tail length=57 mm; weight=5 g'),\n",
    "            {'key': 'total length', 'value': '111', 'units': 'mm'})\n",
    "    \n",
    "    def test_8(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('unformatted measurements=Verbatim weight=X;ToL=230;TaL=115;HF=22;E=18; ; total length=230 mm; tail length=115 mm;'),\n",
    "            {'key': 'total length', 'value': '230', 'units': 'mm'})\n",
    "    \n",
    "    def test_9(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('** Body length =345 cm; Blubber=1 cm '),\n",
    "            {'key': 'Body length', 'value': '345', 'units': 'cm'})\n",
    "\n",
    "    def test_10(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('t.l.= 2 feet 3.1 - 4.5 inches '),\n",
    "            {'key': 't.l.', 'value': ['2', '3.1 - 4.5'], 'units': ['feet', 'inches']})\n",
    "\n",
    "    def test_11(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('2 ft. 3.1 - 4.5 in. '),\n",
    "            {'key': '_english_', 'value': ['2', '3.1 - 4.5'], 'units': ['ft.', 'in.']})\n",
    "\n",
    "    def test_12(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('total length= 2 ft.'),\n",
    "            {'key': 'total length', 'value': '2', 'units': 'ft.'})\n",
    "\n",
    "    def test_13(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('AJR-32   186-102-23-15  15.0g'),\n",
    "            {'key': '_shorthand_', 'value': '186', 'units': '_mm_'})\n",
    "\n",
    "    def test_14(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('length=8 mm'),\n",
    "            {'key': 'length', 'value': '8', 'units': 'mm'})\n",
    "\n",
    "    def test_15(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('another; length=8 mm'),\n",
    "            {'key': 'length', 'value': '8', 'units': 'mm'})\n",
    "    \n",
    "    def test_16(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('another; TL_120, noise'),\n",
    "            {'key': 'TL_', 'value': '120', 'units': None})\n",
    "    \n",
    "    def test_17(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('another; TL - 101.3mm, noise'),\n",
    "            {'key': 'TL', 'value': '101.3','units': 'mm'})\n",
    "     \n",
    "    def test_18(self):\n",
    "        self.assertDictEqual(\n",
    "           target.parse('before; TL153, after'),\n",
    "            {'key': 'TL', 'value': '153', 'units': None})\n",
    "\n",
    "    def test_19(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('before; Total length in catalog and specimen tag as 117, after'),\n",
    "            {'key': 'Total length', 'value': '117', 'units': None})\n",
    "    \n",
    "    def test_20(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('before Snout vent lengths range from 16 to 23 mm. after'),\n",
    "            {'key': 'Snout vent lengths', 'value': '16 to 23', 'units': 'mm.'})\n",
    "    \n",
    "    def test_21(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('Size=13 cm TL'),\n",
    "            {'key': 'TL', 'value': '13', 'units': 'cm'})\n",
    "    \n",
    "    def test_22(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('det_comments:31.5-58.3inTL'),\n",
    "            {'key': 'TL', 'value': '31.5-58.3', 'units': 'in'})\n",
    "    \n",
    "    def test_23(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('SVL52mm'),\n",
    "            {'key': 'SVL', 'value': '52', 'units': 'mm'})\n",
    "    \n",
    "    def test_24(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('snout-vent length=221 mm; total length=257 mm; tail length=36 mm'),\n",
    "            {'key': 'total length', 'value': '257', 'units': 'mm'})\n",
    "    \n",
    "    def test_25(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('SVL 209 mm, total 272 mm, 4.4 g.'),\n",
    "            {'key': 'total', 'value': '272', 'units': 'mm'})\n",
    "    \n",
    "    def test_26(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('{\"time collected\":\"0712-0900\", \"length\":\"12.0\" }'),\n",
    "            {'key': 'length', 'value': '12.0', 'units': None})\n",
    "    \n",
    "    def test_27(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('{\"time collected\":\"1030\", \"water depth\":\"1-8\", \"bottom\":\"abrupt lava cliff dropping off to sand at 45 ft.\", \"length\":\"119-137\" }'),\n",
    "            {'key': 'length', 'value': '119-137', 'units': None})\n",
    "    \n",
    "    def test_28(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('TL (mm) 44,SL (mm) 38,Weight (g) 0.77 xx'),\n",
    "            {'key': 'TL', 'value': '44', 'units': 'mm'})\n",
    "    \n",
    "    def test_29(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('{\"totalLengthInMM\":\"270-165-18-22-31\", '),\n",
    "            {'key': 'totalLengthInMM', 'value': '270', 'units': 'MM'})\n",
    "    \n",
    "    def test_30(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('{\"length\":\"20-29\" }'),\n",
    "            {'key': 'length', 'value': '20-29', 'units': None})\n",
    "    \n",
    "    def test_31(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('field measurements on fresh dead specimen were 157-60-20-19-21g'),\n",
    "            {'key': '_shorthand_', 'value': '157', 'units': '_mm_'})\n",
    "\n",
    "    def test_32(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('f age class: adult; standard length: 63-107mm'),\n",
    "            {'key': 'standard length', 'value': '63-107', 'units': 'mm'})\n",
    "\n",
    "    def test_33(self):\n",
    "        self.assertEqual(\n",
    "            target.parse('Rehydrated in acetic acid 7/1978-8/1987.'),\n",
    "            None)\n",
    "\n",
    "    def test_34(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('age class: adult; standard length: 18.0-21.5mm'),\n",
    "            {'key': 'standard length', 'value': '18.0-21.5', 'units': 'mm'})\n",
    "\n",
    "    def test_35(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('age class: adult; standard length: 18-21.5mm'),\n",
    "            {'key': 'standard length', 'value': '18-21.5', 'units': 'mm'})\n",
    "\n",
    "    def test_36(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('age class: adult; standard length: 18.0-21mm'),\n",
    "            {'key': 'standard length', 'value': '18.0-21', 'units': 'mm'})\n",
    "\n",
    "    def test_37(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('age class: adult; standard length: 18-21mm'),\n",
    "            {'key': 'standard length', 'value': '18-21', 'units': 'mm'})\n",
    "    \n",
    "    def test_38(self):\n",
    "        self.assertEqual(\n",
    "            target.parse(\"Specimen #'s - 5491,5492,5498,5499,5505,5526,5527,5528,5500,5507,5508,5590,5592,5595,5594,5593,5596,5589,5587,5586,5585\"),\n",
    "            None)\n",
    "\n",
    "    def test_39(self):\n",
    "        self.assertEqual(\n",
    "            target.parse('20-28mm SL'),\n",
    "            {'key': 'SL', 'value': '20-28', 'units': 'mm'})\n",
    "\n",
    "    def test_40(self):\n",
    "        self.assertEqual(\n",
    "            target.parse('29mm SL'),\n",
    "            {'key': 'SL', 'value': '29', 'units': 'mm'})\n",
    "    \n",
    "    def test_41(self):\n",
    "        self.assertEqual(\n",
    "            target.parse('{\"measurements\":\"159-?-22-16=21.0\" }'),\n",
    "            {'key': 'measurements', 'value': '159', 'units': '_mm_'})\n",
    "\n",
    "    def test_42(self):\n",
    "        self.assertEqual(\n",
    "            target.parse('c701563b-dbd9-4500-184f-1ad61eb8da11'),\n",
    "            None)\n",
    "\n",
    "\n",
    "suite = unittest.defaultTestLoader.loadTestsFromTestCase(TestTotalLengthParsing)\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Body Mass Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Body Mass Parsing Regular Expression Fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MASS_FRAGMENTS = MASS_LENGTH_FRAGMENTS + r'''\n",
    "    (?(DEFINE)\n",
    "\n",
    "        # Used to indicate that the next measurement in a shorthand notation is total mass\n",
    "        (?P<wt_shorthand_sep> [=\\s\\-]+ )\n",
    "\n",
    "        # Shorthand notation\n",
    "        (?P<wt_shorthand> (?: (?: (?&number) | (?&shorthand_unknown) ) (?&shorthand_sep) ){3,}\n",
    "                          (?: (?&number) | (?&shorthand_unknown) ) (?&wt_shorthand_sep) )\n",
    "\n",
    "        # Shorthand notation requiring units\n",
    "        (?P<wt_shorthand_req> (?: (?: (?&number) | (?&shorthand_unknown) ) (?&shorthand_sep) ){4,} )\n",
    "\n",
    "        # A common shorthand notation\n",
    "        (?P<wt_shorthand_euro> (?: (?&number) | (?&shorthand_unknown) ) hb\n",
    "                               (?: (?&shorthand_sep) (?: (?<! [\\w\\-] ) (?&number)\n",
    "                                 | (?&shorthand_unknown) )[a-z]* ){4,} = )\n",
    "\n",
    "        # Keywords for total mass\n",
    "        (?P<total_wt_key> weightingrams | massingrams\n",
    "                        | (?: body | full | observed | total ) (?&dot) \\s* (?&wt_key_word)\n",
    "        )\n",
    "\n",
    "        # Keywords often used for total mass\n",
    "        (?P<other_wt_key> (?: dead | live ) (?&dot) \\s* (?&wt_key_word) )\n",
    "\n",
    "        #  Weight keyword\n",
    "        (?P<wt_key_word> weights?\n",
    "                       | weigh (?: s | ed | ing )\n",
    "                       | mass\n",
    "                       | w (?&dot) t s? (?&dot)\n",
    "        )\n",
    "\n",
    "        # Gather all weight keys\n",
    "        (?P<all_wt_keys>  (?&total_wt_key)  | (?&other_wt_key) | (?&wt_key_word)\n",
    "                       |  (?&key_units_req) | (?&shorthand_words) | (?&shorthand_typos))\n",
    "\n",
    "        # Look for phrases with the total weight\n",
    "        (?P<wt_in_phrase> total \\s+ (?&wt_key_word) )\n",
    "\n",
    "        # Mass unit words\n",
    "        (?P<wt_units_word> (?: gram | milligram | kilogram | pound | ounce ) s? )\n",
    "\n",
    "        # Mass unit abbreviations\n",
    "        (?P<wt_units_abbrev> (?: m (?&dot) g | k (?&dot) g | g[mr]? | lb | oz ) s? (?&dot) )\n",
    "\n",
    "        # All mass units\n",
    "        (?P<wt_units> (?&wt_units_word) | (?&wt_units_abbrev) )\n",
    "\n",
    "        # Use to parse forms like: 2 lbs 4 oz.\n",
    "        (?P<wt_pound> (?: pound | lb ) s? (?&dot) )\n",
    "        (?P<wt_ounce> (?: ounce | oz ) s? (?&dot) )\n",
    "    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body Mass Parsing Regular Expression Battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BODY_MASS = RegexpBattery(parse_units=True, units_from_key=r''' (?P<units> grams ) $ ''')\n",
    "\n",
    "# Look for a pattern like: body mass: 4 lbs 8 oz\n",
    "BODY_MASS.append(\n",
    "    'en_wt',\n",
    "    MASS_FRAGMENTS + r'''\n",
    "         \\b (?P<key>    (?&all_wt_keys))? (?&key_end)?\n",
    "            (?P<value1> (?&range))  \\s*\n",
    "            (?P<units1> (?&wt_pound))  \\s*\n",
    "            (?P<value2> (?&range))  \\s*\n",
    "            (?P<units2> (?&wt_ounce))\n",
    "    ''',\n",
    "    default_key='_english_',\n",
    "    compound_value=2\n",
    ")\n",
    "\n",
    "# Look for body mass with a total weight key and optional units\n",
    "BODY_MASS.append(\n",
    "    'total_wt_key',\n",
    "    MASS_FRAGMENTS + r'''\n",
    "         \\b (?P<key>   (?&total_wt_key)) (?&key_end)\n",
    "            (?P<value> (?&range)) \\s*\n",
    "            (?P<units> (?&wt_units))?\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Look for these secondary body mass keys next\n",
    "BODY_MASS.append(\n",
    "    'other_wt_key',\n",
    "    MASS_FRAGMENTS + r'''\n",
    "         \\b (?P<key>   (?&other_wt_key)) (?&key_end)\n",
    "            (?P<value> (?&range)) \\s*\n",
    "            (?P<units> (?&wt_units))?\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Look for keys where the units are required\n",
    "BODY_MASS.append(\n",
    "    'key_units_req',\n",
    "    MASS_FRAGMENTS + r'''\n",
    "         \\b (?P<key>   (?&key_units_req)) (?&key_end)\n",
    "            (?P<value> (?&range)) \\s*\n",
    "            (?P<units> (?&wt_units))\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Look for the body mass in a phrase\n",
    "BODY_MASS.append(\n",
    "    'wt_in_phrase',\n",
    "    MASS_FRAGMENTS + r'''\n",
    "         \\b (?P<key>   (?&wt_in_phrase)) \\D{1,32}\n",
    "            (?P<value> (?&range)) \\s*\n",
    "            (?P<units> (?&wt_units))?\n",
    "    '''\n",
    ")\n",
    "\n",
    "# An out of order parse: body mass (g) 20-25\n",
    "BODY_MASS.append(\n",
    "    'wt_key_word',\n",
    "    MASS_FRAGMENTS + r'''\n",
    "         \\b (?P<key>   (?&wt_key_word)) \\s*\n",
    "            (?&open) \\s* (?P<units> (?&wt_units)) \\s* (?&close) \\s*\n",
    "            (?P<value> (?&range))\n",
    "    '''\n",
    ")\n",
    "\n",
    "# These keys require units to disambiguate what is being measured\n",
    "BODY_MASS.append(\n",
    "    'wt_key_word_req',\n",
    "    MASS_FRAGMENTS + r'''\n",
    "         (?P<key>   (?&wt_key_word)) (?&key_end)\n",
    "         (?P<value> (?&range)) \\s*\n",
    "         (?P<units> (?&wt_units))\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Body mass is in shorthand notation\n",
    "BODY_MASS.append(\n",
    "    'wt_shorthand',\n",
    "    MASS_FRAGMENTS + r'''\n",
    "         \\b (?: (?P<key> (?&all_wt_keys)) (?&key_end) )?\n",
    "            (?&wt_shorthand) \\s*\n",
    "            (?P<value> (?&number)) \\s*\n",
    "            (?P<units> (?&wt_units))?\n",
    "    ''',\n",
    "    default_key='_shorthand_'\n",
    ")\n",
    "\n",
    "# Body mass is in shorthand notation (units required)\n",
    "BODY_MASS.append(\n",
    "    'wt_shorthand_req',\n",
    "    MASS_FRAGMENTS + r'''\n",
    "         \\b (?: (?P<key> (?&all_wt_keys)) (?&key_end) )?\n",
    "            (?&wt_shorthand_req) \\s*\n",
    "            (?P<value> (?&number)) \\s*\n",
    "            (?P<units> (?&wt_units))\n",
    "    ''',\n",
    "    default_key='_shorthand_'\n",
    ")\n",
    "\n",
    "# A shorthand notation with some abbreviations in it\n",
    "BODY_MASS.append(\n",
    "    'wt_shorthand_euro',\n",
    "    MASS_FRAGMENTS + r'''\n",
    "         \\b (?: (?P<key> (?&all_wt_keys)) (?&key_end) )?\n",
    "            (?&wt_shorthand_euro) \\s*\n",
    "            (?P<value> (?&number)) \\s*\n",
    "            (?P<units> (?&wt_units))?\n",
    "    ''',\n",
    "    default_key='_shorthand_'\n",
    ")\n",
    "\n",
    "# A notation using 'fa'. It can be shorter than the other shorthand notations\n",
    "BODY_MASS.append(\n",
    "    'wt_fa',\n",
    "    MASS_FRAGMENTS + r'''\n",
    "         fa \\d* -\n",
    "         (?P<value> (?&number)) \\s*\n",
    "         (?P<units> (?&wt_units))?\n",
    "    ''',\n",
    "    default_key='_shorthand_'\n",
    ")\n",
    "\n",
    "# Now we can look for the body mass, RANGE, optional units\n",
    "BODY_MASS.append(\n",
    "    'wt_key_ambiguous',\n",
    "    MASS_FRAGMENTS + r'''\n",
    "         (?P<key>   (?&wt_key_word)) (?&key_end)\n",
    "         (?P<value> (?&range)) \\s*\n",
    "         (?P<units> (?&wt_units))?\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Body Mass Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..........................\n",
      "----------------------------------------------------------------------\n",
      "Ran 26 tests in 0.075s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=26 errors=0 failures=0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = BODY_MASS\n",
    "\n",
    "class TestBodyMassParsing(unittest.TestCase):\n",
    "\n",
    "    def test_1(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('762-292-121-76 2435.0g'),\n",
    "            {'key': '_shorthand_', 'value': '2435.0', 'units': 'g'})\n",
    "\n",
    "    def test_2(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('TL (mm) 44,SL (mm) 38,Weight (g) 0.77 xx'),\n",
    "            {'key': 'Weight', 'value': '0.77', 'units': 'g'})\n",
    "\n",
    "    def test_3(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('Note in catalog: Mus. SW Biol. NK 30009; 91-0-17-22-62g'),\n",
    "            {'key': '_shorthand_', 'value': '62', 'units': 'g'})\n",
    "\n",
    "    def test_4(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('body mass=20 g'),\n",
    "            {'key': 'body mass', 'value': '20', 'units': 'g'})\n",
    "\n",
    "    def test_5(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('2 lbs. 3.1 - 4.5 oz '),\n",
    "            {'key': '_english_', 'value': ['2', '3.1 - 4.5'], 'units': ['lbs.', 'oz']})\n",
    "\n",
    "    def test_6(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('{\"totalLengthInMM\":\"x\", \"earLengthInMM\":\"20\", \"weight\":\"[139.5] g\" }'),\n",
    "            {'key': 'weight', 'value': '[139.5]', 'units': 'g'})\n",
    "\n",
    "    def test_7(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('{\"fat\":\"No fat\", \"gonads\":\"Testes 10 x 6 mm.\", \"molt\":\"No molt\", \"stomach contents\":\"Not recorded\", \"weight\":\"94 gr.\"'),\n",
    "            {'key': 'weight', 'value': '94', 'units': 'gr.'})\n",
    "\n",
    "    def test_8(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('Note in catalog: 83-0-17-23-fa64-35g'),\n",
    "            {'key': '_shorthand_', 'value': '35', 'units': 'g'})\n",
    "\n",
    "    def test_9(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('{\"measurements\":\"20.2g, SVL 89.13mm\" }'),\n",
    "            {'key': 'measurements', 'value': '20.2', 'units': 'g'})\n",
    "\n",
    "    def test_10(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('Body: 15 g'),\n",
    "            {'key': 'Body', 'value': '15', 'units': 'g'})\n",
    "\n",
    "    def test_11(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('82-00-15-21-tr7-fa63-41g'),\n",
    "            {'key': '_shorthand_', 'value': '41', 'units': 'g'})\n",
    "\n",
    "    def test_12(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('weight=5.4 g; unformatted measurements=77-30-7-12=5.4'),\n",
    "            {'key': 'weight', 'value': '5.4', 'units': 'g'})\n",
    "\n",
    "    def test_13(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('unformatted measurements=77-30-7-12=5.4; weight=5.4;'),\n",
    "            {'key': 'measurements', 'value': '5.4', 'units': None})\n",
    "\n",
    "    def test_14(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('{\"totalLengthInMM\":\"270-165-18-22-31\", '),\n",
    "            {'key': '_shorthand_', 'value': '31', 'units': None})\n",
    "\n",
    "    def test_15(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('{\"measurements\":\"143-63-20-17=13 g\" }'),\n",
    "            {'key': 'measurements', 'value': '13', 'units': 'g'})\n",
    "\n",
    "    def test_16(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('143-63-20-17=13'),\n",
    "            {'key': '_shorthand_', 'value': '13', 'units': None})\n",
    "\n",
    "    def test_17(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('reproductive data: Testes descended -10x7 mm; sex: male; unformatted measurements: 181-75-21-18=22 g'),\n",
    "            {'key': 'measurements', 'value': '22', 'units': 'g'})\n",
    "\n",
    "    def test_18(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('{ \"massInGrams\"=\"20.1\" }'),\n",
    "            {'key': 'massInGrams', 'value': '20.1', 'units': 'Grams'})\n",
    "\n",
    "    def test_19(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse(' {\"gonadLengthInMM_1\":\"10\", \"gonadLengthInMM_2\":\"6\", \"weight\":\"1,192.0\" }'),\n",
    "            {'key': 'weight', 'value': '1,192.0', 'units': None})\n",
    "\n",
    "    def test_20(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('\"weight: 20.5-31.8'),\n",
    "            {'key': 'weight', 'value': '20.5-31.8', 'units': None})\n",
    "\n",
    "    def test_21(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('\"weight: 20.5-32'),\n",
    "            {'key': 'weight', 'value': '20.5-32', 'units': None})\n",
    "\n",
    "    def test_22(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('\"weight: 21-31.8'),\n",
    "            {'key': 'weight', 'value': '21-31.8', 'units': None})\n",
    "\n",
    "    def test_23(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('\"weight: 21-32'),\n",
    "            {'key': 'weight', 'value': '21-32', 'units': None})\n",
    "\n",
    "    def test_24(self):\n",
    "        self.assertEqual(\n",
    "            target.parse(\"Specimen #'s - 5491,5492,5498,5499,5505,5526,5527,5528,5500,5507,5508,5590,5592,5595,5594,5593,5596,5589,5587,5586,5585\"),\n",
    "            None)\n",
    "\n",
    "    def test_25(self):\n",
    "        self.assertDictEqual(\n",
    "            target.parse('weight=5.4 g; unformatted measurements=77-x-7-12=5.4'),\n",
    "            {'key': 'weight', 'value': '5.4', 'units': 'g'})\n",
    "\n",
    "    def test_26(self):\n",
    "        self.assertEqual(\n",
    "            target.parse('c701563b-dbd9-4500-184f-1ad61eb8da11'),\n",
    "            None)\n",
    "\n",
    "\n",
    "suite = unittest.defaultTestLoader.loadTestsFromTestCase(TestBodyMassParsing)\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the Raw Trait Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Warning: This function is, currently, several times slower than the Perl version.**\n",
    "\n",
    "This function uses the regular expression batteries to parse the VertNet traits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The new columns we will put the raw (unnormalized) extracted data into\n",
    "# Along with the regular expression batter used to parse the value\n",
    "raw_trait_columns = [\n",
    "    dict(column='autoextract_sex',          battery=SEX),\n",
    "    dict(column='autoextract_life_stage',   battery=LIFE_STAGE),\n",
    "    dict(column='autoextract_total_length', battery=TOTAL_LENGTH),\n",
    "    dict(column='autoextract_body_mass',    battery=BODY_MASS)\n",
    "]\n",
    "\n",
    "\n",
    "def extract_raw_traits():\n",
    "    with open(VERTNET_FILE_NAME, 'r') as in_file, open(RAW_FILE_NAME, 'w') as out_file:\n",
    "        reader  = csv.DictReader(in_file)\n",
    "        headers = reader.fieldnames + [c['column'] for c in raw_trait_columns]\n",
    "        writer  = csv.DictWriter(out_file, headers)\n",
    "        writer.writeheader()\n",
    "        for row in reader:\n",
    "            for r in raw_trait_columns:\n",
    "                cell = {}\n",
    "                for v in VERTNET_SEARCH_COLUMNS:\n",
    "                    string = row[v]\n",
    "                    string = ' '.join(string.strip().split())\n",
    "                    trait  = r['battery'].parse(string)\n",
    "                    if trait:\n",
    "                        cell[v] = trait\n",
    "                if cell:\n",
    "                    row[r['column']] = json.dumps(cell)\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "# extract_raw_traits()  # Uncomment me to run the extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Extracted Keys and Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extracted_words = [\n",
    "    dict(column='autoextract_total_length', json_field='key'),\n",
    "    dict(column='autoextract_total_length', json_field='units'),\n",
    "    dict(column='autoextract_body_mass',    json_field='key'),\n",
    "    dict(column='autoextract_body_mass',    json_field='units')\n",
    "]\n",
    "\n",
    "\n",
    "def get_extracted_word_counts(column_name, json_field):\n",
    "    cnt = Counter()\n",
    "    with open(RAW_FILE_NAME, 'r') as in_file:\n",
    "        reader = csv.DictReader(in_file)\n",
    "        for row in reader:\n",
    "            cell = row[column_name]\n",
    "            if not cell:\n",
    "                continue\n",
    "            jcell = json.loads(cell)\n",
    "            for key, obj in jcell.items():\n",
    "                if isinstance(obj[json_field], list):\n",
    "                    word = ' '.join(obj[json_field])\n",
    "                else:\n",
    "                    word = obj[json_field]\n",
    "                if word:\n",
    "                    cnt[word.lower()] += 1\n",
    "    return cnt\n",
    "\n",
    "\n",
    "def get_extracted_words():\n",
    "    for target in extracted_words:\n",
    "        words = get_extracted_word_counts(target['column'], target['json_field'])\n",
    "        out_file_name = '{0}{1}_{2}.txt'.format(BASE_FILE_NAME, target['column'],  target['json_field'])\n",
    "        with open(out_file_name, 'w') as out_file:\n",
    "            for word, n in sorted(words.items()):\n",
    "                out_file.write(word + '\\n')\n",
    "\n",
    "\n",
    "# get_extracted_words()  # Uncomment me to get the extracted words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion Factors for Total Length and Body Mass Traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the output from the extracted keys and units above, these are the length search keys we found and their normalized equivalents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEN_KEY = {\n",
    "    '_english_'                   : 'total length',\n",
    "    '_shorthand_'                 : 'total length',\n",
    "    'body'                        : 'head-body length',\n",
    "    'body length'                 : 'head-body length',\n",
    "    'catalog'                     : 'total length',\n",
    "    'fork length'                 : 'fork length',\n",
    "    'forklength'                  : 'fork length',\n",
    "    'headbodylengthinmillimeters' : 'head-body length',\n",
    "    'length'                      : 'total length',\n",
    "    'lengthinmillimeters'         : 'total length',\n",
    "    'lengths'                     : 'total length',\n",
    "    'max length'                  : 'total length',\n",
    "    'maxlength'                   : 'total length',\n",
    "    'mean length'                 : 'total length',\n",
    "    'meas'                        : 'total length',\n",
    "    'meas,'                       : 'total length',\n",
    "    'meas.'                       : 'total length',\n",
    "    'meas. h.b.'                  : 'head-body length',\n",
    "    'measurement'                 : 'total length',\n",
    "    'measurements'                : 'total length',\n",
    "    'measurements are'            : 'total length',\n",
    "    'measurements made'           : 'total length',\n",
    "    'measurements of'             : 'total length',\n",
    "    'measurements questionable'   : 'total length',\n",
    "    'measurements read'           : 'total length',\n",
    "    'measurements reads'          : 'total length',\n",
    "    'measurementsnt'              : 'total length',\n",
    "    'mesurements'                 : 'total length',\n",
    "    'on tag'                      : 'total length',\n",
    "    's.l'                         : 'standard length',\n",
    "    's.l.'                        : 'standard length',\n",
    "    'sl'                          : 'standard length',\n",
    "    'sl.'                         : 'standard length',\n",
    "    'snout vent length'           : 'snout-vent length',\n",
    "    'snout vent lengths'          : 'snout-vent length',\n",
    "    'snout-vent length'           : 'snout-vent length',\n",
    "    'snout-vent lengths'          : 'snout-vent length',\n",
    "    'snoutventlengthinmm'         : 'snout-vent length',\n",
    "    'specimen'                    : 'total length',\n",
    "    'specimens'                   : 'total length',\n",
    "    'standard length'             : 'standard length',\n",
    "    'svl'                         : 'snout-vent length',\n",
    "    'svl.'                        : 'snout-vent length',\n",
    "    't.l'                         : 'total length',\n",
    "    't.l.'                        : 'total length',\n",
    "    'tag'                         : 'total length',\n",
    "    'tl'                          : 'total length',\n",
    "    'tl.'                         : 'total length',\n",
    "    'tl_'                         : 'total length',\n",
    "    'tol'                         : 'total length',\n",
    "    'total'                       : 'total length',\n",
    "    'total length'                : 'total length',\n",
    "    'total length in mm'          : 'total length',\n",
    "    'total lengths'               : 'total length',\n",
    "    'totallength'                 : 'total length',\n",
    "    'totallengthinmm'             : 'total length',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the output from the extracted keys and units above, these are the length units we found and their normalized equivalents. We are normalizing to millimeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEN_UNITS = {\n",
    "    ''             : 1.0,\n",
    "    '_mm_'         : 1.0,\n",
    "    'c.m.'         : 10.0,\n",
    "    'centimeters'  : 10.0,\n",
    "    'cm'           : 10.0,\n",
    "    'cm.'          : 10.0,\n",
    "    'cm.s'         : 10.0,\n",
    "    'cms'          : 10.0,\n",
    "    'feet'         : 304.8,\n",
    "    'feet inch'    : [304.8, 25.4],\n",
    "    'feet inches'  : [304.8, 25.4],\n",
    "    'feet inches.' : [304.8, 25.4],\n",
    "    'foot'         : 304.8,\n",
    "    'foot inch'    : [304.8, 25.4],\n",
    "    'foot inches'  : [304.8, 25.4],\n",
    "    'foot inches.' : [304.8, 25.4],\n",
    "    'ft'           : 304.8,\n",
    "    'ft in'        : [304.8, 25.4],\n",
    "    'ft in.'       : [304.8, 25.4],\n",
    "    'ft inches'    : [304.8, 25.4],\n",
    "    'ft inches.'   : [304.8, 25.4],\n",
    "    'ft ins.'      : [304.8, 25.4],\n",
    "    'ft.'          : 304.8,\n",
    "    'ft. in'       : [304.8, 25.4],\n",
    "    'ft. in.'      : [304.8, 25.4],\n",
    "    'ft. inches'   : [304.8, 25.4],\n",
    "    'ft. ins'      : [304.8, 25.4],\n",
    "    'in'           : 25.4,\n",
    "    'in.'          : 25.4,\n",
    "    'inch'         : 25.4,\n",
    "    'inches'       : 25.4,\n",
    "    'ins'          : 25.4,\n",
    "    'm.m'          : 1.0,\n",
    "    'm.m.'         : 1.0,\n",
    "    'meter'        : 1000.0,\n",
    "    'meters'       : 1000.0,\n",
    "    'millimeter'   : 1.0,\n",
    "    'millimeters'  : 1.0,\n",
    "    'mm'           : 1.0,\n",
    "    'mm.'          : 1.0,\n",
    "    'mm.s'         : 1.0,\n",
    "    'mms'          : 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the output from the extracted keys and units above, these are the length search keys we found and their normalized equivalents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MASS_KEY = {\n",
    "    '_english_'                 : 'total weight',\n",
    "    '_shorthand_'               : 'total weight',\n",
    "    'body'                      : 'total weight',\n",
    "    'body mass'                 : 'total weight',\n",
    "    'body weight'               : 'total weight',\n",
    "    'body wt'                   : 'total weight',\n",
    "    'body wt.'                  : 'total weight',\n",
    "    'bodymass'                  : 'total weight',\n",
    "    'catalog'                   : 'total weight',\n",
    "    'dead. weight'              : 'total weight',\n",
    "    'dead. wt'                  : 'total weight',\n",
    "    'dead. wt.'                 : 'total weight',\n",
    "    'full.weight'               : 'total weight',\n",
    "    'live weight'               : 'total weight',\n",
    "    'live wt'                   : 'total weight',\n",
    "    'live wt.'                  : 'total weight',\n",
    "    'mass'                      : 'total weight',\n",
    "    'massingrams'               : 'total weight',\n",
    "    'meas'                      : 'total weight',\n",
    "    'meas.'                     : 'total weight',\n",
    "    'measurement'               : 'total weight',\n",
    "    'measurements'              : 'total weight',\n",
    "    'measurements are'          : 'total weight',\n",
    "    'measurements questionable' : 'total weight',\n",
    "    'measurements read'         : 'total weight',\n",
    "    'measurements reads'        : 'total weight',\n",
    "    'mesurements'               : 'total weight',\n",
    "    'observedweight'            : 'total weight',\n",
    "    'on tag'                    : 'total weight',\n",
    "    'specimen'                  : 'total weight',\n",
    "    'total'                     : 'total weight',\n",
    "    'total weight'              : 'total weight',\n",
    "    'total wt'                  : 'total weight',\n",
    "    'total wt.'                 : 'total weight',\n",
    "    'w.t.'                      : 'total weight',\n",
    "    'weighed'                   : 'total weight',\n",
    "    'weighing'                  : 'total weight',\n",
    "    'weighs'                    : 'total weight',\n",
    "    'weight'                    : 'total weight',\n",
    "    'weightingrams'             : 'total weight',\n",
    "    'weights'                   : 'total weight',\n",
    "    'wt'                        : 'total weight',\n",
    "    'wt.'                       : 'total weight',\n",
    "    'wts'                       : 'total weight',\n",
    "    'wts.'                      : 'total weight',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the output from the extracted keys and units above, these are the mass units we found and their normalized equivalents. We are normalizing to grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MASS_UNITS = {\n",
    "    ''               : 1.0,\n",
    "    'g'              : 1.0,\n",
    "    'g.'             : 1.0,\n",
    "    'gm'             : 1.0,\n",
    "    'gm.'            : 1.0,\n",
    "    'gms'            : 1.0,\n",
    "    'gms.'           : 1.0,\n",
    "    'gr'             : 1.0,\n",
    "    'gr.'            : 1.0,\n",
    "    'gram'           : 1.0,\n",
    "    'grams'          : 1.0,\n",
    "    'grs'            : 1.0,\n",
    "    'kg'             : 1000.0,\n",
    "    'kg.'            : 1000.0,\n",
    "    'kgs'            : 1000.0,\n",
    "    'kgs.'           : 1000.0,\n",
    "    'kilograms'      : 1000.0,\n",
    "    'lb'             : 453.593,\n",
    "    'lb oz'          : [453.593, 28.349],\n",
    "    'lb oz.'         : [453.593, 28.349],\n",
    "    'lb ozs'         : [453.593, 28.349],\n",
    "    'lb.'            : 453.593,\n",
    "    'lb. oz'         : [453.593, 28.349],\n",
    "    'lb. oz.'        : [453.593, 28.349],\n",
    "    'lb. ozs'        : [453.593, 28.349],\n",
    "    'lb. ozs.'       : [453.593, 28.349],\n",
    "    'lbs'            : 453.593,\n",
    "    'lbs oz'         : [453.593, 28.349],\n",
    "    'lbs oz.'        : [453.593, 28.349],\n",
    "    'lbs ozs'        : [453.593, 28.349],\n",
    "    'lbs.'           : 453.593,\n",
    "    'lbs. oz'        : [453.593, 28.349],\n",
    "    'lbs. oz.'       : [453.593, 28.349],\n",
    "    'lbs. ozs.'      : [453.593, 28.349],\n",
    "    'mg'             : 0.001,\n",
    "    'mg.'            : 0.001,\n",
    "    'mgs.'           : 0.001,\n",
    "    'ounce'          : 28.349,\n",
    "    'ounces'         : 28.349,\n",
    "    'oz'             : 28.349,\n",
    "    'oz.'            : 28.349,\n",
    "    'ozs'            : 28.349,\n",
    "    'ozs.'           : 28.349,\n",
    "    'pound'          : 453.593,\n",
    "    'pound ounces'   : [453.593, 28.349],\n",
    "    'pound oz'       : [453.593, 28.349],\n",
    "    'pounds'         : 453.593,\n",
    "    'pounds ounces'  : [453.593, 28.349],\n",
    "    'pounds ounces.' : [453.593, 28.349],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the Total Length and Body Mass Traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quanity_is_range = regex.compile(r'- | to', flags=regex.IGNORECASE | regex.VERBOSE)\n",
    "\n",
    "\n",
    "def normalize_key(raw_cell, key_conversions):\n",
    "    key = None\n",
    "    if 'key' in raw_cell and raw_cell['key']:\n",
    "        if raw_cell['key'].lower() in key_conversions:\n",
    "            key = key_conversions[raw_cell['key'].lower()]\n",
    "    return key\n",
    "\n",
    "\n",
    "def is_inferred(units):\n",
    "    if units:\n",
    "        return units[0] == '_'\n",
    "    return True\n",
    "\n",
    "\n",
    "def multiply(value, units):\n",
    "    value = regex.sub(r'[^\\d\\.]', '', value)\n",
    "    precision = 0\n",
    "    parts = value.split('.')\n",
    "    if len(parts) > 1:\n",
    "        precision = len(parts[1])\n",
    "    result = round(float(value) * units, precision)\n",
    "    return result if precision else int(result)\n",
    "    \n",
    "\n",
    "def normalize_cell(row, input_column, key_conversions, unit_conversions, default_units):\n",
    "    if not row[input_column]:\n",
    "        return None\n",
    "    \n",
    "    raw_data = json.loads(row[input_column])\n",
    "    \n",
    "    for column in VERTNET_SEARCH_COLUMNS:\n",
    "        if column not in row[input_column]:\n",
    "            continue\n",
    "        raw_cell = raw_data[column]\n",
    "        \n",
    "        key = normalize_key(raw_cell, key_conversions)\n",
    "        \n",
    "        if isinstance(raw_cell['units'], list):\n",
    "            units  = ' '.join(raw_cell['units']).lower()\n",
    "            value  = multiply(raw_cell['value'][0], unit_conversions[units][0])\n",
    "            value += multiply(raw_cell['value'][1], unit_conversions[units][1])\n",
    "            return(key, value)\n",
    "        \n",
    "        units = raw_cell['units'].lower() if raw_cell['units'] else default_units\n",
    "        \n",
    "        inferred = is_inferred(raw_cell['units'])\n",
    "        \n",
    "        if quanity_is_range.search(raw_cell['value']):\n",
    "            values = quanity_is_range.split(raw_cell['value'])\n",
    "            return (key, (multiply(values[0], unit_conversions[units]),\n",
    "                          multiply(values[1], unit_conversions[units])))\n",
    "        if inferred:\n",
    "            return (key, multiply(raw_cell['value'], unit_conversions[units]), 'units inferred')\n",
    "        else:\n",
    "            return (key, multiply(raw_cell['value'], unit_conversions[units]))\n",
    "\n",
    "\n",
    "def normalize():\n",
    "    with open(RAW_FILE_NAME, 'r') as in_file, open(NORMALIZED_FILE_NAME, 'w') as out_file:\n",
    "        reader  = csv.DictReader(in_file)\n",
    "        headers = reader.fieldnames + ['normalized_total_length', 'normalized_body_mass']\n",
    "        writer  = csv.DictWriter(out_file, headers)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for row in reader:\n",
    "            normalized_len = normalize_cell(row, 'autoextract_total_length', LEN_KEY,  LEN_UNITS, 'mm')\n",
    "            if normalized_len:\n",
    "                row['normalized_total_length'] = json.dumps(normalized_len)\n",
    "            normalized_wt  = normalize_cell(row, 'autoextract_body_mass',    MASS_KEY, MASS_UNITS, 'g')\n",
    "            if normalized_wt:\n",
    "                row['normalized_body_mass'] = json.dumps(normalized_wt)\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "# normalize()  # Uncomment me if you want to normalize the extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the Total Number of Extracts for Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_counted = ['autoextract_sex', 'autoextract_life_stage']\n",
    "columns_normalized = ['normalized_total_length', 'normalized_body_mass']\n",
    "df = pd.read_csv(NORMALIZED_FILE_NAME, dtype=np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_normalized():\n",
    "    for column in columns_normalized:\n",
    "        df_not_null = df.loc[df[column].notnull(), ('class', column)]\n",
    "        df_not_null['inferred'] = df_not_null[column].str.contains('\"units inferred\"')\n",
    "        ctab = pd.crosstab(df_not_null['class'], df_not_null['inferred'], margins=True)\n",
    "        out_file_name = '{0}{1}_counts.txt'.format(BASE_FILE_NAME, column)\n",
    "        with open(out_file_name, 'w') as out_file:\n",
    "            out_file.write('{} Counts:\\n\\n'.format(column))\n",
    "            out_file.write(ctab.to_string())\n",
    "\n",
    "\n",
    "def count_columns():\n",
    "    for column in columns_counted:\n",
    "        df_not_null = df.loc[df[column].notnull(), ('class', column)]\n",
    "        out_file_name = '{0}{1}_counts.txt'.format(BASE_FILE_NAME, column)\n",
    "        with open(out_file_name, 'w') as out_file:\n",
    "            out_file.write('{} Counts:\\n\\n'.format(column))\n",
    "            out_file.write(df_not_null['class'].value_counts().to_string())\n",
    "            out_file.write('\\n\\nTotal Count: {}\\n'.format(len(df_not_null)))\n",
    "\n",
    "\n",
    "count_normalized()  # Uncomment me if you want to count the classes for each column extract\n",
    "count_columns()  # Uncomment me if you want to count the classes for each column extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top](#Table-of-Contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
